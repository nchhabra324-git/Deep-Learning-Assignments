{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OR1idVh26Gy1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TODO: load the glass dataset into df\n",
        "df = pd.read_csv(\"glass.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: check number of rows and columns\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BzaPHps6ygD",
        "outputId": "e09c6d4b-5693-45eb-d716-67895e6e5166"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(214, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: see column names\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fclCfE8M6zcK",
        "outputId": "b12a9477-911f-4ea3-878a-f1bbbe76d5c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: look at first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1hNIvdvQ62VS",
        "outputId": "1b00d216-d61e-4c12-99f2-952bbd7ac27f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
              "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
              "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
              "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
              "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
              "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0be61f13-e6e4-4438-b052-3de45a8c7c31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RI</th>\n",
              "      <th>Na</th>\n",
              "      <th>Mg</th>\n",
              "      <th>Al</th>\n",
              "      <th>Si</th>\n",
              "      <th>K</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Ba</th>\n",
              "      <th>Fe</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.52101</td>\n",
              "      <td>13.64</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1.10</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.06</td>\n",
              "      <td>8.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.51761</td>\n",
              "      <td>13.89</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.36</td>\n",
              "      <td>72.73</td>\n",
              "      <td>0.48</td>\n",
              "      <td>7.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.51618</td>\n",
              "      <td>13.53</td>\n",
              "      <td>3.55</td>\n",
              "      <td>1.54</td>\n",
              "      <td>72.99</td>\n",
              "      <td>0.39</td>\n",
              "      <td>7.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.51766</td>\n",
              "      <td>13.21</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1.29</td>\n",
              "      <td>72.61</td>\n",
              "      <td>0.57</td>\n",
              "      <td>8.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.51742</td>\n",
              "      <td>13.27</td>\n",
              "      <td>3.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>73.08</td>\n",
              "      <td>0.55</td>\n",
              "      <td>8.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0be61f13-e6e4-4438-b052-3de45a8c7c31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0be61f13-e6e4-4438-b052-3de45a8c7c31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0be61f13-e6e4-4438-b052-3de45a8c7c31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 214,\n  \"fields\": [\n    {\n      \"column\": \"RI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0030368637393854334,\n        \"min\": 1.51115,\n        \"max\": 1.53393,\n        \"num_unique_values\": 178,\n        \"samples\": [\n          1.51966,\n          1.51808,\n          1.51969\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Na\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8166035557149829,\n        \"min\": 10.73,\n        \"max\": 17.38,\n        \"num_unique_values\": 142,\n        \"samples\": [\n          14.38,\n          13.02,\n          13.83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4424078448704414,\n        \"min\": 0.0,\n        \"max\": 4.49,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          3.86,\n          3.47,\n          2.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Al\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49926964560048454,\n        \"min\": 0.29,\n        \"max\": 3.5,\n        \"num_unique_values\": 118,\n        \"samples\": [\n          1.48,\n          1.65,\n          1.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Si\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7745457947651124,\n        \"min\": 69.81,\n        \"max\": 75.41,\n        \"num_unique_values\": 133,\n        \"samples\": [\n          72.22,\n          73.06,\n          71.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6521918455589802,\n        \"min\": 0.0,\n        \"max\": 6.21,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          0.47,\n          0.31,\n          0.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4231534872813945,\n        \"min\": 5.43,\n        \"max\": 16.19,\n        \"num_unique_values\": 143,\n        \"samples\": [\n          12.5,\n          8.52,\n          11.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ba\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4972192605997036,\n        \"min\": 0.0,\n        \"max\": 3.15,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          0.64,\n          0.61,\n          1.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09743870063650086,\n        \"min\": 0.0,\n        \"max\": 0.51,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.51,\n          0.03,\n          0.21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Data Preprocessing & Binary Label Creation\n",
        "- What this step does: Loads the glass data, checks its shape/columns, converts the target column (Type) into a binary 0/1 format (where Type == 1 is our positive class), and separates the features (X) from the labels (y).\n",
        "\n",
        "- Why it is needed: Machine learning models require mathematical arrays to train. Since we are building a binary classifier, we must convert the multi class target into a simple binary outcome (1 or 0) so the math works."
      ],
      "metadata": {
        "id": "SODpxpK_9IwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: create binary labels\n",
        "df[\"y\"] = (df[\"Type\"] ==1).astype(int)\n",
        "\n",
        "# TODO: remove original Type column\n",
        "df = df.drop(columns=[\"Type\"])\n"
      ],
      "metadata": {
        "id": "oFzU7st_65A6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: separate features and labels\n",
        "X = df.drop(columns=[\"y\"]).values\n",
        "y = df[\"y\"].values"
      ],
      "metadata": {
        "id": "SIZb4Pra69xy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Train-Test Split\n",
        "\n",
        "- What this step does: Divides the dataset into two chunks: 80% for training the model and 20% kept hidden for testing.\n",
        "\n",
        "- Why it is needed: If we evaluate the model on the same data it learned from, it's like giving a student the answer key before a test. Splitting the data ensures we can measure how well the model generalizes to completely new, unseen data."
      ],
      "metadata": {
        "id": "DrOF7jGi9f3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# TODO: split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "QWp6-qMq7Cdj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Feature Scaling\n",
        "\n",
        "- What this step does: Standardizes the features so they all have a mean of 0 and a standard deviation of 1 using StandardScaler.\n",
        "\n",
        "- Why it is needed: Different features have wildly different ranges. Without scaling, the weight updates would be dominated by the larger numbers, causing the Gradient Descent algorithm to struggle, bounce around, and converge very slowly."
      ],
      "metadata": {
        "id": "ihj-Xwlb9x0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# TODO: scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "q4Stn0L27H2a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Sigmoid and Probability Prediction\n",
        "- What this step does: Takes the linear equation z = X * w + b and passes it through the sigmoid function 1 / (1 + e^{-z}).\n",
        "\n",
        "- Why it is needed: The linear equation outputs raw scores that can range from -infinity to +infinity. The sigmoid function gracefully \"squashes\" these scores into a range strictly between 0 and 1, allowing us to interpret the output as a probability."
      ],
      "metadata": {
        "id": "1SxQaAvH-Ori"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "# TODO: return sigmoid of z\n",
        "  return 1 / (1 + np.exp(-z))\n"
      ],
      "metadata": {
        "id": "PNMno3DA7LLq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_proba(X, w, b):\n",
        "# TODO: compute z using weights and bias\n",
        "  z = X @ w + b\n",
        "# TODO: convert z to probability\n",
        "  p = sigmoid(z)\n",
        "  return p\n"
      ],
      "metadata": {
        "id": "SEDyT6vF7LGb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Loss Function\n",
        "- What this step does: Calculates the error between the model's predicted probabilities (p) and the actual true labels (y) using logarithmic math.\n",
        "\n",
        "- Why it is needed: Unlike the basic perceptron that just checks right or wrong, Log Loss heavily penalizes the model if it is confidently wrong. This creates a smooth error landscape that Gradient Descent can easily navigate."
      ],
      "metadata": {
        "id": "HirSiiNi-yXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y, p):\n",
        "# TODO: compute binary cross entropy\n",
        "  return -np.mean(y*np.log(p) + (1-y)*np.log(1-p))\n"
      ],
      "metadata": {
        "id": "UomxXIC57cXz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Weight Updates & Training Loop\n",
        "- What this step does: Iteratively calculates the gradient (the direction of the steepest error) and updates the weights (w) and bias (b) by a fraction of the learning rate.\n",
        "\n",
        "- Why it is needed: This is the actual learning engine. By repeating this process over multiple epochs, the model slowly adjusts its weights until the loss function is minimized."
      ],
      "metadata": {
        "id": "w766Emt0_KpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_weights(X, y, w, b, lr):\n",
        "# TODO: compute predictions\n",
        "  p = predict_proba(X, w, b)\n",
        "# TODO: compute error\n",
        "  error = p - y\n",
        "# TODO: update weights and bias\n",
        "  w = w - lr * (X.T @ error) /len(y)\n",
        "  b = b - lr * np.mean(error)\n",
        "  return w, b\n"
      ],
      "metadata": {
        "id": "qPR3lMjt7fmy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: initialize weights and bias\n",
        "w = np.zeros(X_train.shape[1])\n",
        "b =0.0\n",
        "lr =0.1\n",
        "epochs =100\n",
        "for _ in range(epochs):\n",
        "  w, b = update_weights(X_train, y_train, w, b, lr)\n"
      ],
      "metadata": {
        "id": "0Bvmebf-7kjC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(p, threshold=0.5):\n",
        "  return (p >= threshold).astype(int)\n"
      ],
      "metadata": {
        "id": "m2T0IDzF7uzC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- how this differs from perceptron\n",
        "- why sigmoid matters\n",
        "- what problem still remains unsolved\n",
        "\n",
        "Unlike a standard perceptron that outputs a rigid, discrete binary step (0 or 1) and updates weights based on raw error, this logistic regression model outputs a continuous probability and updates weights using gradient descent on a smooth loss function. The sigmoid function matters because it enables this smooth, differentiable transition, mapping any linear output into a bounded [0, 1] probability space so the model can learn nuanced confidence levels rather than just making hard guesses. However, despite being a probabilistic upgrade, one major problem remains unsolved: logistic regression is still fundamentally a linear classifier. It can only draw a straight flat decision boundary and will completely fail on datasets that are not linearly separable (like the XOR problem we talked about earlier) unless we step up to a Multi-Layer Perceptron (Neural Network)."
      ],
      "metadata": {
        "id": "ln1FmmW98n36"
      }
    }
  ]
}